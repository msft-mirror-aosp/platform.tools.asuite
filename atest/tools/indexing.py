#!/usr/bin/env python3
# Copyright 2019, The Android Open Source Project
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Atest indexing module."""

# pylint: disable=line-too-long

from __future__ import print_function

import functools
import logging
import os
import pickle
import shutil
import subprocess
import sys
import tempfile
import time

from atest import atest_utils as au
from atest import constants

from atest.atest_enum import DetectType
from atest.metrics import metrics, metrics_utils

UPDATEDB = 'updatedb'
LOCATE = 'locate'
SEARCH_TOP = os.getenv(constants.ANDROID_BUILD_TOP, '')
# The list was generated by command:
# find `gettop` -type d -wholename `gettop`/out -prune  -o -type d -name '.*'
# -print | awk -F/ '{{print $NF}}'| sort -u
PRUNENAMES = ['.abc', '.appveyor', '.azure-pipelines',
              '.bazelci', '.build-id', '.buildkite', '.buildscript',
              '.cargo', '.ci', '.circleci', '.clusterfuzzlite', '.conan',
              '.devcontainer',
              '.dwz',
              '.externalToolBuilders',
              '.git', '.githooks', '.github', '.gitlab', '.gitlab-ci', '.google',
              '.hidden',
              '.idea', '.intermediates',
              '.jenkins',
              '.kokoro',
              '.libs_cffi_backend',
              '.more', '.mvn',
              '.prebuilt_info', '.private', '__pycache__',
              '.repo',
              '.settings', '.static', '.svn',
              '.test',
              '.travis',
              '.travis_scripts',
              '.tx',
              '.vscode']
PRUNEPATHS = ['prebuilts']


def debug_log(func):
    """Decorator for logging with debug mode."""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        logging.debug(f'Running {func.__name__}...')
        func(*args, **kwargs)
        logging.debug(f'{func.__name__} done.')
    return wrapper


def run_updatedb(search_root=SEARCH_TOP, output_cache=constants.LOCATE_CACHE,
                 **kwargs):
    """Run updatedb and generate cache in $ANDROID_HOST_OUT/indices/plocate.db

    Args:
        search_root: The path of the search root(-U).
        output_cache: The filename of the updatedb cache(-o).
        kwargs: (optional)
            prunepaths: A list of paths unwanted to be searched(-e).
            prunenames: A list of dirname that won't be cached(-n).
    """
    prunenames = kwargs.pop('prunenames', ' '.join(PRUNENAMES))
    _prunepaths = [os.path.join(SEARCH_TOP, p) for p in PRUNEPATHS]
    _prunepaths.append(str(au.get_build_out_dir()))
    prunepaths = kwargs.pop('prunepaths', ' '.join(_prunepaths))
    if kwargs:
        raise TypeError('Unexpected **kwargs: %r' % kwargs)
    updatedb_cmd = [UPDATEDB, '-l0']
    updatedb_cmd.append('-U%s' % search_root)
    updatedb_cmd.append('-n%s' % prunenames)
    updatedb_cmd.append('-o%s' % output_cache)
    # (b/206866627) /etc/updatedb.conf excludes /mnt from scanning on Linux.
    # Use --prunepaths to override the default configuration.
    updatedb_cmd.append('--prunepaths')
    updatedb_cmd.append(prunepaths)
    # Support scanning bind mounts as well.
    updatedb_cmd.extend(['--prune-bind-mounts', 'no'])

    logging.debug('Running updatedb... ')
    try:
        full_env_vars = os.environ.copy()
        logging.debug('Executing: %s', updatedb_cmd)
        if not os.path.isdir(constants.INDEX_DIR):
            os.makedirs(constants.INDEX_DIR)
        subprocess.run(updatedb_cmd, env=full_env_vars, check=True)
    except (KeyboardInterrupt, SystemExit):
        logging.error('Process interrupted or failure.')
    # Delete indices when plocate.db is locked() or other CalledProcessError.
    # (b/141588997)
    except subprocess.CalledProcessError as err:
        logging.error('Executing %s error.', UPDATEDB)
        metrics_utils.handle_exc_and_send_exit_event(
            constants.PLOCATEDB_LOCKED)
        if err.output:
            logging.error(err.output)
        os.remove(output_cache)


def _dump_index(dump_file, output, output_re, key, value):
    """Dump indexed data with pickle.

    Args:
        dump_file: A string of absolute path of the index file.
        output: A string generated by locate and grep.
        output_re: An regex which is used for grouping patterns.
        key: A string for dictionary key, e.g. classname, package,
             cc_class, etc.
        value: A set of path.

    The data structure will be like:
    {
      'Foo': {'/path/to/Foo.java', '/path2/to/Foo.kt'},
      'Boo': {'/path3/to/Boo.java'}
    }
    """
    temp_file = tempfile.NamedTemporaryFile()
    _dict = {}
    with open(temp_file.name, 'wb') as cache_file:
        if isinstance(output, bytes):
            output = output.decode()
        for entry in output.splitlines():
            match = output_re.match(entry)
            if match:
                _dict.setdefault(match.group(key), set()).add(
                    match.group(value))
        try:
            pickle.dump(_dict, cache_file, protocol=2)
        except IOError:
            logging.error('Failed in dumping %s', dump_file)
    shutil.copy(temp_file.name, dump_file)
    temp_file.close()


# pylint: disable=anomalous-backslash-in-string
def get_cc_result(locatedb=constants.LOCATE_CACHE, **kwargs):
    """Search all testable cc/cpp and grep TEST(), TEST_F() or TEST_P().

    After searching cc/cpp files, index corresponding data types in parallel.

    Args:
        locatedb: A string of the absolute path of the plocate.db
        kwargs: (optional)
            cc_class_index: A path string of the CC class index.
    """
    find_cc_cmd = (
        f"{LOCATE} -id{locatedb} --regex '/*.test.*\.(cc|cpp)$'"
        f"| xargs egrep -sH '{constants.CC_GREP_RE}' 2>/dev/null || true")
    logging.debug('Probing CC classes:\n %s', find_cc_cmd)
    result = subprocess.check_output(find_cc_cmd, shell=True)

    cc_class_index = kwargs.pop('cc_class_index', constants.CC_CLASS_INDEX)
    au.run_multi_proc(func=_index_cc_classes, args=[result, cc_class_index])


# pylint: disable=anomalous-backslash-in-string
def get_java_result(locatedb=constants.LOCATE_CACHE, **kwargs):
    """Search all testable java/kt and grep package.

    After searching java/kt files, index corresponding data types in parallel.

    Args:
        locatedb: A string of the absolute path of the plocate.db
        kwargs: (optional)
            class_index: A path string of the Java class index.
            qclass_index: A path string of the qualified class index.
            package_index: A path string of the package index.
    """
    package_grep_re = r'^\s*package\s+[a-z][[:alnum:]]+[^{]'
    find_java_cmd = (
        f"{LOCATE} -id{locatedb} --regex '/*.test.*\.(java|kt)$' "
        # (b/204398677) suppress stderr when indexing target terminated.
        f"| xargs egrep -sH '{package_grep_re}' 2>/dev/null|| true")
    logging.debug('Probing Java classes:\n %s', find_java_cmd)
    result = subprocess.check_output(find_java_cmd, shell=True)

    class_index = kwargs.pop('class_index', constants.CLASS_INDEX)
    qclass_index = kwargs.pop('qclass_index', constants.QCLASS_INDEX)
    package_index = kwargs.pop('package_index', constants.PACKAGE_INDEX)
    au.run_multi_proc(func=_index_java_classes, args=[result, class_index])
    au.run_multi_proc(func=_index_qualified_classes, args=[result, qclass_index])
    au.run_multi_proc(func=_index_packages, args=[result, package_index])


@debug_log
def _index_cc_classes(output, index):
    """Index CC classes.

    The data structure is like:
    {
      'FooTestCase': {'/path1/to/the/FooTestCase.cpp',
                      '/path2/to/the/FooTestCase.cc'}
    }

    Args:
        output: A string object generated by get_cc_result().
        index: A string path of the index file.
    """
    _dump_index(dump_file=index, output=output,
                output_re=constants.CC_OUTPUT_RE,
                key='test_name', value='file_path')


@debug_log
def _index_java_classes(output, index):
    """Index Java classes.
    The data structure is like:
    {
        'FooTestCase': {'/path1/to/the/FooTestCase.java',
                        '/path2/to/the/FooTestCase.kt'}
    }

    Args:
        output: A string object generated by get_java_result().
        index: A string path of the index file.
    """
    _dump_index(dump_file=index, output=output,
                output_re=constants.CLASS_OUTPUT_RE,
                key='class', value='java_path')


@debug_log
def _index_packages(output, index):
    """Index Java packages.
    The data structure is like:
    {
        'a.b.c.d': {'/path1/to/a/b/c/d/',
                    '/path2/to/a/b/c/d/'
    }

    Args:
        output: A string object generated by get_java_result().
        index: A string path of the index file.
    """
    _dump_index(dump_file=index,
                output=output, output_re=constants.PACKAGE_OUTPUT_RE,
                key='package', value='java_dir')


@debug_log
def _index_qualified_classes(output, index):
    """Index Fully Qualified Java Classes(FQCN).
    The data structure is like:
    {
        'a.b.c.d.FooTestCase': {'/path1/to/a/b/c/d/FooTestCase.java',
                                '/path2/to/a/b/c/d/FooTestCase.kt'}
    }

    Args:
        output: A string object generated by get_java_result().
        index: A string path of the index file.
    """
    temp_file = tempfile.NamedTemporaryFile()
    _dict = {}
    with open(temp_file.name, 'wb') as cache_file:
        if isinstance(output, bytes):
            output = output.decode()
        for entry in output.split('\n'):
            match = constants.QCLASS_OUTPUT_RE.match(entry)
            if match:
                fqcn = match.group('package') + '.' + match.group('class')
                _dict.setdefault(fqcn, set()).add(match.group('java_path'))
        try:
            pickle.dump(_dict, cache_file, protocol=2)
        except (KeyboardInterrupt, SystemExit):
            logging.error('Process interrupted or failure.')
        except IOError:
            logging.error('Failed in dumping %s', index)
    shutil.copy(temp_file.name, index)
    temp_file.close()


def index_targets(output_cache=constants.LOCATE_CACHE):
    """The entrypoint of indexing targets.

    Utilise plocate database to index reference types of CLASS, CC_CLASS,
    PACKAGE and QUALIFIED_CLASS.

    (b/206886222) The checksum and file size of plocate.db may differ even the
    src is not changed at all; therefore, it will skip indexing when both
    conditions are fulfilled:
      - not undergo `repo sync` before running atest.
      - file numbers recorded in current and previous plocate.db are the same.

    Args:
        output_cache: A file path of the updatedb cache
                      (e.g. /path/to/plocate.db).
    """
    start = time.time()
    unavailable_cmds = [
        cmd for cmd in [UPDATEDB, LOCATE] if not au.has_command(cmd)]
    if unavailable_cmds:
        logging.debug('command %s is unavailable; skip indexing...',
                      ' '.join(unavailable_cmds))
        return

    # Get the amount of indexed files.
    get_num_cmd = f'{LOCATE} -d{output_cache} --count /'
    ret, pre_number = subprocess.getstatusoutput(get_num_cmd)
    if ret != 0:
        logging.debug('Failed to run %s', get_num_cmd)
        pre_number = sys.maxsize

    run_updatedb(SEARCH_TOP, output_cache)
    checksum_file = au.get_index_path('repo_sync.md5')
    repo_syncd = not au.check_md5(checksum_file, missing_ok=False)
    if repo_syncd:
        repo_file = au.get_build_top('.repo/.repo_fetchtimes.json')
        au.run_multi_proc(
            func=au.save_md5,
            args=[[repo_file], checksum_file])
    if not repo_syncd and pre_number == subprocess.getoutput(get_num_cmd):
        logging.debug('%s remains the same. Ignore indexing', output_cache)
        return
    logging.debug('Indexing targets... ')
    proc_java = au.run_multi_proc(func=get_java_result, args=[output_cache])
    proc_cc = au.run_multi_proc(func=get_cc_result, args=[output_cache])
    proc_java.join()
    proc_cc.join()
    elapsed_time = time.time() - start
    logging.debug('Indexing targets took %ss', elapsed_time)
    metrics.LocalDetectEvent(
            detect_type=DetectType.INDEX_TARGETS_MS,
            result=int(elapsed_time * 1000))

if __name__ == '__main__':
    if not os.getenv(constants.ANDROID_HOST_OUT, ''):
        sys.exit()
    index_targets()
